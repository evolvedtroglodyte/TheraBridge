# =============================================================================
# TherapyBridge Backend - Environment Configuration Template
# =============================================================================
# Copy this file to .env and fill in your values
# Then run: cp .env.example .env

# =============================================================================
# REQUIRED CONFIGURATION
# =============================================================================
# These fields MUST be configured for the application to run

# ============================================
# Database Configuration (REQUIRED)
# ============================================
# Get free PostgreSQL database from: https://neon.tech
# After signup, copy the connection string from your Neon dashboard
DATABASE_URL=postgresql://user:password@host:5432/therapybridge?sslmode=require

# Database Connection Pool Settings (optional, sensible defaults provided)
# CRITICAL: Total connections = WORKERS * (DB_POOL_SIZE + DB_MAX_OVERFLOW)
# Current config: 1 worker * (10 + 20) = 30 total connections
# If scaled to 4 workers: 4 * (10 + 20) = 120 total connections
#
# Neon PostgreSQL Connection Limits:
#   - Free tier: ~100 connections
#   - Paid tier: varies by plan (check your plan limits)
#   - Exceeding limits causes "too many connections" errors
#
# WORKER SCALING WARNING:
# Before increasing WORKERS, calculate total connections:
#   - 2 workers: 2 * 30 = 60 connections (safe for free tier)
#   - 4 workers: 4 * 30 = 120 connections (EXCEEDS free tier limit)
#   - 8 workers: 8 * 30 = 240 connections (requires paid tier)
#
# Production recommendations for multi-worker deployment:
#   - 2-4 workers: DB_POOL_SIZE=5, DB_MAX_OVERFLOW=10 (15 per worker = 30-60 total)
#   - 4-8 workers: DB_POOL_SIZE=3, DB_MAX_OVERFLOW=7 (10 per worker = 40-80 total)
#   - Always verify: WORKERS * (POOL_SIZE + MAX_OVERFLOW) < database connection limit
#
DB_POOL_SIZE=10              # Number of connections to maintain in pool
DB_MAX_OVERFLOW=20           # Additional connections when pool is full
DB_POOL_TIMEOUT=30           # Seconds to wait for available connection

# SQL Query Logging - CRITICAL: MUST be false in production (exposes PHI)
SQL_ECHO=false

# ============================================
# Security Configuration (REQUIRED)
# ============================================
# CRITICAL: Generate secure random keys for production
# Generate with: openssl rand -hex 32

# JWT Secret Key (REQUIRED)
# Used to sign and verify authentication tokens
# Changing this key invalidates all existing user sessions
JWT_SECRET_KEY=your-secret-key-here-change-in-production

# Encryption Master Key (REQUIRED)
# Used to encrypt sensitive data at rest (e.g., PHI, PII)
# NEVER change this in production - encrypted data becomes unrecoverable
# Generate with: openssl rand -hex 32
ENCRYPTION_MASTER_KEY=your-encryption-master-key-here-change-in-production

# JWT Settings (optional, defaults provided)
JWT_ALGORITHM=HS256                  # Signing algorithm
ACCESS_TOKEN_EXPIRE_MINUTES=30       # Access token lifetime
REFRESH_TOKEN_EXPIRE_DAYS=7          # Refresh token lifetime

# ============================================
# OpenAI API Configuration (REQUIRED)
# ============================================
# Get API key from: https://platform.openai.com/api-keys
# Required for AI-powered note extraction from therapy session transcripts
OPENAI_API_KEY=sk-your-openai-api-key-here

# OpenAI Model Settings (optional, defaults provided)
OPENAI_MODEL=gpt-4o                  # Model for note extraction
OPENAI_TIMEOUT=120                   # API timeout in seconds
OPENAI_MAX_RETRIES=3                 # Number of retry attempts
OPENAI_TEMPERATURE=0.3               # Temperature (0.0-2.0, lower = more consistent)

# =============================================================================
# OPTIONAL CONFIGURATION
# =============================================================================
# These fields have sensible defaults and can be customized as needed

# ============================================
# Environment Configuration
# ============================================
# Deployment environment: development, staging, or production
ENVIRONMENT=development

# Debug mode - CRITICAL: MUST be false in production to prevent PHI exposure
# Enabling debug mode exposes Protected Health Information (PHI) in error messages
DEBUG=false

# ============================================
# CORS Configuration
# ============================================
# Allowed frontend origins (comma-separated list)
# Default: http://localhost:3000,http://localhost:5173
# Production: Set to your actual frontend URL(s)
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# Allow credentials in CORS requests (default: true)
CORS_CREDENTIALS=true

# ============================================
# File Upload Configuration
# ============================================
# Upload directory for audio files (default: uploads/audio)
UPLOAD_DIR=uploads/audio

# Maximum upload size in megabytes (default: 100)
MAX_UPLOAD_SIZE_MB=100

# Allowed audio formats (comma-separated, default: mp3,wav,m4a,ogg,flac)
ALLOWED_AUDIO_FORMATS=mp3,wav,m4a,ogg,flac

# ============================================
# Rate Limiting Configuration
# ============================================
# Enable rate limiting (default: true)
RATE_LIMIT_ENABLED=true

# Rate limits by endpoint (format: count/period)
RATE_LIMIT_LOGIN=5/minute        # Login attempts
RATE_LIMIT_SIGNUP=3/hour         # Signup attempts
RATE_LIMIT_REFRESH=10/minute     # Token refresh attempts
RATE_LIMIT_API=100/minute        # General API calls

# ============================================
# Server Configuration
# ============================================
# Server host and port (optional, defaults provided)
HOST=0.0.0.0
PORT=8000
WORKERS=1

# ============================================
# Logging Configuration
# ============================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL (default: INFO)
LOG_LEVEL=INFO

# Log format (default provided in config.py)
# LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# ============================================
# Email Service Configuration (OPTIONAL)
# ============================================
# TherapyBridge supports three email providers for sending verification emails,
# password resets, and notifications. Choose one based on your deployment needs.
# If not configured, email features will be disabled.

# Email provider: smtp, sendgrid, ses, or disabled (default: disabled)
EMAIL_PROVIDER=disabled

# From email address (sender) - MUST be verified in your email provider
EMAIL_FROM=noreply@therapybridge.com

# Frontend URL for email verification links and password reset links
FRONTEND_URL=http://localhost:3000

# --------------------------------------------
# Option 1: SMTP Configuration
# --------------------------------------------
# Use any SMTP server (Gmail, Mailgun, SendInBlue, custom SMTP)
# Recommended for: Development, small deployments
#
# Common SMTP providers:
# - Gmail: smtp.gmail.com:587 (requires App Password, not regular password)
#   Setup: https://support.google.com/accounts/answer/185833
# - Mailgun: smtp.mailgun.org:587
#   Setup: https://www.mailgun.com
# - SendInBlue: smtp-relay.sendinblue.com:587
#   Setup: https://www.sendinblue.com

SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password

# Gmail Setup Instructions:
# 1. Enable 2-factor authentication: https://myaccount.google.com/security
# 2. Generate App Password: https://myaccount.google.com/apppasswords
# 3. Use the 16-character App Password as SMTP_PASSWORD

# --------------------------------------------
# Option 2: SendGrid Configuration
# --------------------------------------------
# API-based email delivery with analytics and deliverability monitoring
# Recommended for: Production (non-AWS), analytics-focused deployments
#
# Setup:
# 1. Sign up: https://sendgrid.com (free tier: 100 emails/day)
# 2. Create API key: Settings → API Keys → Create API Key
# 3. Select "Mail Send" permission
# 4. Verify sender email or domain
#
# Uncomment and configure if using SendGrid:
# EMAIL_PROVIDER=sendgrid
# SENDGRID_API_KEY=SG.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#
# Install SendGrid SDK:
# pip install sendgrid
# pip freeze > requirements.txt

# --------------------------------------------
# Option 3: AWS SES Configuration
# --------------------------------------------
# Amazon Simple Email Service - cost-effective for high volume
# Recommended for: AWS deployments, high-volume email ($0.10 per 1,000 emails)
#
# Setup:
# 1. AWS Console → Amazon SES: https://console.aws.amazon.com/ses
# 2. Verify email address: Identities → Create Identity
# 3. Request production access (initially in sandbox mode)
# 4. Create IAM user with AmazonSESFullAccess permission
# 5. Generate access key and secret key
#
# Uncomment and configure if using AWS SES:
# EMAIL_PROVIDER=ses
# AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
# AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
# AWS_DEFAULT_REGION=us-east-1
#
# Install boto3 (AWS SDK):
# pip install boto3
# pip freeze > requirements.txt

# ============================================
# AWS S3 Storage Configuration (OPTIONAL)
# ============================================
# For storing audio files in S3 instead of local filesystem
# Recommended for: Production deployments, multi-instance scaling
#
# Setup:
# 1. AWS Console → S3: https://console.aws.amazon.com/s3
# 2. Create bucket (e.g., therapybridge-audio-prod)
# 3. Create IAM user with S3 access
# 4. Generate access key and secret key
#
# Uncomment and configure if using S3:
# AWS_S3_BUCKET=therapybridge-audio-prod
# AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
# AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
# AWS_DEFAULT_REGION=us-east-1
#
# Install boto3 (AWS SDK):
# pip install boto3
# pip freeze > requirements.txt

# ============================================
# Analytics & Scheduler Configuration
# ============================================
# Enable background jobs for analytics aggregation (default: true)
ENABLE_ANALYTICS_SCHEDULER=true

# Hour (0-23 UTC) to run daily analytics aggregation (default: 0 = midnight UTC)
DAILY_AGGREGATION_HOUR=0

# Analytics cache TTL in seconds (default: 300 = 5 minutes)
ANALYTICS_CACHE_TTL_SECONDS=300

# ============================================
# Cleanup Configuration
# ============================================
# Retention period for failed sessions (days, default: 7)
# Audio files from sessions with status='failed' older than this will be cleaned up
FAILED_SESSION_RETENTION_DAYS=7

# Retention period for orphaned files (hours, default: 24)
# Files not referenced in database and older than this will be cleaned up
ORPHANED_FILE_RETENTION_HOURS=24

# Enable automatic cleanup on startup (default: false)
# When true, runs cleanup automatically when the API starts
AUTO_CLEANUP_ON_STARTUP=false

# Scheduled cleanup hour (0-23, default: 3)
# Reserved for future scheduled cleanup feature (currently not implemented)
CLEANUP_SCHEDULE_HOUR=3

# ============================================
# GPU Transcription Configuration (OPTIONAL)
# ============================================
# Enable GPU-accelerated transcription using CUDA-enabled NVIDIA GPU
# Recommended for: High-volume deployments, Vast.ai/RunPod GPU instances
#
# GPU Requirements:
#   - NVIDIA GPU with CUDA support (compute capability 3.5+)
#   - CUDA Toolkit 11.8 or higher
#   - PyTorch with CUDA support (not CPU-only version)
#   - Minimum 8GB VRAM (16GB recommended for large Whisper models)
#
# Setup:
#   1. Install GPU dependencies: pip install -r audio-transcription-pipeline/requirements.txt
#   2. Verify CUDA: python -c "import torch; print(torch.cuda.is_available())"
#   3. Set USE_GPU_PIPELINE=true
#
# Fallback behavior:
#   If GPU transcription fails (CUDA error, OOM, etc.), automatically falls back to CPU
#
# Default: false (uses CPU/API-based transcription)
USE_GPU_PIPELINE=false

# Path to audio-transcription-pipeline directory (optional)
# If not set, uses monorepo structure (../audio-transcription-pipeline)
# Set this if deploying backend and pipeline separately
# AUDIO_PIPELINE_DIR=/path/to/audio-transcription-pipeline

# =============================================================================
# QUICK START CHECKLIST
# =============================================================================
# [ ] 1. Copy this file: cp .env.example .env
# [ ] 2. Get Neon PostgreSQL: https://neon.tech → Copy DATABASE_URL
# [ ] 3. Get OpenAI API key: https://platform.openai.com/api-keys
# [ ] 4. Generate JWT secret: openssl rand -hex 32
# [ ] 5. Generate encryption key: openssl rand -hex 32
# [ ] 6. (Optional) Configure email provider if needed
# [ ] 7. (Optional) Configure AWS S3 if using cloud storage
# [ ] 8. Run migrations: alembic upgrade head
# [ ] 9. Start server: uvicorn app.main:app --reload
