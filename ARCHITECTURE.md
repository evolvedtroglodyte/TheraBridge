# TherapyBridge Architecture Map

Comprehensive guide to the entire codebase structure, data flow, and integration points.

---

## Table of Contents
1. [System Overview](#system-overview)
2. [Architecture Diagram](#architecture-diagram)
3. [Backend Structure](#backend-structure)
4. [Frontend Structure](#frontend-structure)
5. [Audio Pipeline](#audio-pipeline)
6. [Data Flow](#data-flow)
7. [Key Integration Points](#key-integration-points)
8. [Current Implementation Status](#current-implementation-status)
9. [Critical Files Reference](#critical-files-reference)

---

## System Overview

TherapyBridge is a three-layer distributed system:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 1: FRONTEND (Next.js 16 + React 19 + Tailwind)       ‚îÇ
‚îÇ  - Patient Dashboard (dashboard-v3)                          ‚îÇ
‚îÇ  - Session Visualization & Analysis                          ‚îÇ
‚îÇ  - AI Chat (Dobby)                                           ‚îÇ
‚îÇ  - Audio Upload Interface                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ HTTP/REST APIs
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 2: BACKEND (FastAPI + Supabase PostgreSQL)           ‚îÇ
‚îÇ  - Session Management                                        ‚îÇ
‚îÇ  - AI Extraction Services (Mood, Topics, Breakthroughs)     ‚îÇ
‚îÇ  - Analysis Orchestration (Wave 1 & Wave 2)                 ‚îÇ
‚îÇ  - Progress Metrics & Deep Analysis                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ File I/O & Data
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 3: AUDIO PIPELINE (Python + OpenAI + pyannote)       ‚îÇ
‚îÇ  - Audio Upload & Preprocessing                             ‚îÇ
‚îÇ  - Whisper Transcription (API or GPU)                        ‚îÇ
‚îÇ  - Speaker Diarization (pyannote 3.1)                       ‚îÇ
‚îÇ  - Speaker Role Detection (Therapist/Client)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Technology Stack

| Component | Technology | Role |
|-----------|-----------|------|
| Frontend | Next.js 16 + React 19 + Tailwind CSS + shadcn/ui | UI/UX, client-side logic |
| Backend | FastAPI + Python 3.13.9 | API endpoints, AI services |
| Database | Supabase (PostgreSQL) + pgvector | Sessions, users, analysis results |
| Auth | Demo mode (frontend) | Development auth flow |
| Transcription | OpenAI Whisper API | Audio to text |
| Diarization | pyannote.audio 3.1 | Speaker detection |
| AI Analysis | GPT-4o / GPT-4o-mini | Topic extraction, mood, breakthroughs |
| Storage | Supabase Storage | Audio file storage |

---

## Architecture Diagram

### Complete Request/Response Flow

```
FRONTEND                          BACKEND                      DATABASE
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Upload     ‚îÇ                ‚îÇ   Upload     ‚îÇ              ‚îÇ Therapy  ‚îÇ
‚îÇ   Page       ‚îÇ‚îÄ‚îÄ‚îÄPOST audio‚îÄ‚îÄ‚ñ∂‚îÇ   Endpoint   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Sessions ‚îÇ
‚îÇ              ‚îÇ                ‚îÇ              ‚îÇ              ‚îÇ Table    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                               ‚îÇ
      ‚îÇ                               ‚îú‚îÄ‚ñ∂ Call OpenAI Whisper (CPU/API)
      ‚îÇ                               ‚îÇ
      ‚îÇ                               ‚îú‚îÄ‚ñ∂ pyannote Diarization
      ‚îÇ                               ‚îÇ
      ‚îÇ                               ‚îî‚îÄ‚ñ∂ Speaker Role Detection
      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Status     ‚îÇ                ‚îÇ   Status     ‚îÇ
‚îÇ   Polling    ‚îÇ‚óÄ‚îÄ‚îÄGET status‚îÄ‚îÄ‚îÇ   Endpoint   ‚îÇ
‚îÇ  (every 2s)  ‚îÇ                ‚îÇ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ
      ‚îú‚îÄ‚ñ∂ When complete: triggers analysis
      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Dashboard  ‚îÇ                ‚îÇ   Demo Init  ‚îÇ
‚îÇ   Loads      ‚îÇ‚îÄ‚îÄ‚îÄGET data‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Endpoint   ‚îÇ
‚îÇ   Sessions   ‚îÇ                ‚îÇ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ
      ‚îú‚îÄ‚ñ∂ usePatientSessions hook
      ‚îú‚îÄ‚ñ∂ Fetches 12 mock sessions OR real API data
      ‚îú‚îÄ‚ñ∂ Displays in SessionCardsGrid
      ‚îÇ
      ‚îî‚îÄ‚ñ∂ AI Chat (Dobby) with context injection
           ‚îú‚îÄ‚ñ∂ Mood trends (from analysis)
           ‚îú‚îÄ‚ñ∂ Technique history
           ‚îú‚îÄ‚ñ∂ Progress indicators
           ‚îî‚îÄ‚ñ∂ Crisis detection keywords
```

---

## Backend Structure

### Directory Layout

```
backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                      # FastAPI app entry point
‚îÇ   ‚îú‚îÄ‚îÄ config.py                    # Environment configuration
‚îÇ   ‚îú‚îÄ‚îÄ database.py                  # Supabase client & helpers
‚îÇ   ‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ demo_auth.py             # Demo mode authentication
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ routers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sessions.py              # Session CRUD + analysis endpoints
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ demo.py                  # Demo initialization endpoints
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îú‚îÄ‚îÄ breakthrough_detector.py # AI breakthrough detection
‚îÇ       ‚îú‚îÄ‚îÄ mood_analyzer.py         # AI mood analysis service
‚îÇ       ‚îú‚îÄ‚îÄ topic_extractor.py       # AI topic extraction
‚îÇ       ‚îú‚îÄ‚îÄ deep_analyzer.py         # Wave 2 deep clinical analysis
‚îÇ       ‚îú‚îÄ‚îÄ prose_generator.py       # Prose narrative generation
‚îÇ       ‚îú‚îÄ‚îÄ speaker_labeler.py       # Therapist/Client role detection
‚îÇ       ‚îú‚îÄ‚îÄ technique_library.py     # Therapeutic technique definitions
‚îÇ       ‚îú‚îÄ‚îÄ analysis_orchestrator.py # Coordinates all analyses
‚îÇ       ‚îî‚îÄ‚îÄ progress_metrics_extractor.py  # Progress tracking
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_full_pipeline.py        # Complete pipeline test
‚îÇ   ‚îú‚îÄ‚îÄ test_mood_analysis.py        # Mood analyzer tests
‚îÇ   ‚îú‚îÄ‚îÄ test_topic_extraction.py     # Topic extractor tests
‚îÇ   ‚îî‚îÄ‚îÄ test_breakthrough_detection.py
‚îú‚îÄ‚îÄ requirements.txt                 # Python dependencies
‚îú‚îÄ‚îÄ .env                             # Environment variables
‚îî‚îÄ‚îÄ README.md
```

### API Endpoints (Sessions Router)

**Base URL:** `http://localhost:8000/api/sessions`

#### Session CRUD
```
GET    /                            # List all sessions (paginated)
POST   /                            # Create new session
GET    /{session_id}                # Get single session with breakthrough details
GET    /patient/{patient_id}        # Get all sessions for a patient
```

#### Transcript & Processing
```
POST   /{session_id}/upload-transcript      # Upload transcript + trigger analysis
POST   /{session_id}/process                # Manually trigger processing
GET    /{session_id}/analysis-status        # Get Wave 1 & Wave 2 status
```

#### Analysis Endpoints
```
POST   /{session_id}/analyze-mood           # Analyze session mood
GET    /patient/{id}/mood-history           # Get mood timeline
POST   /{session_id}/extract-topics         # Extract topics + action items
POST   /{session_id}/analyze-deep           # Wave 2 deep clinical analysis
POST   /{session_id}/detect-breakthrough    # Breakthrough detection
POST   /{session_id}/label-speakers         # Speaker role detection
GET    /{session_id}/techniques             # Get session techniques
GET    /techniques/{technique}/definition   # Look up technique definition
```

#### Reporting
```
GET    /patient/{patient_id}/consistency    # Consistency metrics
GET    /patient/{patient_id}/progress       # Progress metrics summary
```

### Demo Router

**Base URL:** `http://localhost:8000/api/demo`

```
POST   /init               # Initialize demo with token + 12 mock sessions
GET    /status             # Check demo status + analysis progress
POST   /reset              # Clear demo data + reinitialize
```

### Core Services

#### 1. Breakthrough Detector (`breakthrough_detector.py`)
**Purpose:** AI detection of therapeutic breakthroughs (genuine insights, shifts)

**Key Classes:**
- `BreakthroughDetector` - Main service class
- `BreakthroughCandidate` - Detected breakthrough moment
- `SessionBreakthroughAnalysis` - Complete session analysis

**Key Methods:**
```python
analyzer = BreakthroughDetector(api_key)
analysis = analyzer.analyze_session(transcript, session_metadata)

# Returns:
# - has_breakthrough: bool
# - breakthrough_candidates: List[BreakthroughCandidate]
# - primary_breakthrough: BreakthroughCandidate (highest confidence)
# - session_summary: str
# - emotional_trajectory: str
```

**Model:** GPT-4o-mini (cost: ~$0.01/session)

#### 2. Mood Analyzer (`mood_analyzer.py`)
**Purpose:** AI analysis of patient emotional state

**Key Classes:**
- `MoodAnalyzer` - Main service
- `MoodAnalysis` - Mood data with score (0.0-10.0)

**Key Methods:**
```python
analyzer = MoodAnalyzer(api_key)
mood = analyzer.analyze_session(transcript)

# Returns:
# - mood_score: float (0.0-10.0, increments of 0.5)
# - confidence: float (0.0-1.0)
# - rationale: str (why this score)
# - key_indicators: List[str] (emotional signals detected)
# - emotional_tone: str (descriptive label)
```

**Model:** GPT-4o-mini (cost: ~$0.01/session)

#### 3. Topic Extractor (`topic_extractor.py`)
**Purpose:** Extract main topics and action items from session

**Key Classes:**
- `TopicExtractor` - Main service
- `SessionMetadata` - Extracted topics, actions, summary

**Key Methods:**
```python
extractor = TopicExtractor(api_key)
metadata = extractor.extract_session_metadata(transcript)

# Returns:
# - topics: List[str] (1-2 main topics)
# - action_items: List[str] (2 action items)
# - technique: str (primary therapeutic technique)
# - summary: str (max 150 chars, active voice)
# - confidence: float
```

**Model:** GPT-4o-mini (cost: ~$0.01/session)

#### 4. Deep Analyzer (`deep_analyzer.py`)
**Purpose:** Wave 2 analysis - comprehensive clinical insights

**Key Components:**
- Progress indicators (symptom reduction, skill development)
- Therapeutic insights (key realizations, patterns)
- Coping skills assessment
- Therapeutic relationship evaluation
- Recommendations for practice

**Complex nested JSONB structure** stored in database.

#### 5. Analysis Orchestrator (`analysis_orchestrator.py`)
**Purpose:** Coordinates all analyses across waves

**Two-Wave Pipeline:**

**Wave 1 (Immediate):**
- Topic extraction (topics, action items, technique, summary)
- Mood analysis (score, confidence, indicators)
- Completed within seconds

**Wave 2 (Async):**
- Deep clinical analysis (progress, insights, skills, relationship)
- Prose narrative generation
- Breakthrough detection
- Completed within minutes

**Key Functions:**
```python
# Full pipeline (both waves)
result = await analyze_session_full_pipeline(
    session_id, 
    transcript, 
    ai_client
)

# Returns orchestrated results from all services
```

#### 6. Speaker Labeler (`speaker_labeler.py`)
**Purpose:** Identify Therapist vs Client speakers in diarized segments

**Detection Heuristics:**
- First-speaker heuristic (therapist usually opens)
- Speaking ratio heuristic (therapist ~30-40%, client ~60-70%)
- Combined confidence scoring

**Key Functions:**
```python
result = label_session_transcript(
    diarized_segments,  # From pyannote
    therapist_name     # Optional
)

# Returns:
# - therapist_speaker_id: str (e.g., "SPEAKER_00")
# - patient_speaker_id: str (e.g., "SPEAKER_01")
# - confidence: float
# - labeled_transcript: List[Dict]  # With speaker roles
```

#### 7. Technique Library (`technique_library.py`)
**Purpose:** Lookup definitions of therapeutic techniques

**Database:**
```python
TECHNIQUE_DATABASE = {
    "CBT - Cognitive Restructuring": "Identifies and challenges automatic negative thoughts...",
    "DBT - Mindfulness": "Focuses on present-moment awareness...",
    "Motivational Interviewing": "Uses reflective listening to evoke behavior change...",
    # ... 50+ techniques
}
```

---

## Frontend Structure

### Directory Layout

```
frontend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx                   # Root layout with providers
‚îÇ   ‚îú‚îÄ‚îÄ api/                         # API routes (server-side)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ upload/route.ts          # Audio upload to Supabase Storage
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ process/route.ts         # Transcription + diarization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ status/[sessionId]/route.ts  # Processing status polling
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat/route.ts            # AI chat endpoint
‚îÇ   ‚îú‚îÄ‚îÄ patient/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx               # Patient routes layout
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dashboard-v3/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx             # Main dashboard (V3)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SessionCardsGrid.tsx      # Session grid
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SessionCard.tsx           # Individual session card
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ProgressPatternsCard.tsx  # Mood/topic trends
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ NotesGoalsCard.tsx        # Goals display
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ToDoCard.tsx              # Action items
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TimelineSidebar.tsx       # Session timeline
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MajorEventModal.tsx       # Major event details
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ExportDropdown.tsx        # Export options
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ types.ts                  # Type definitions
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ usePatientSessions.ts     # Session data hook
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ mockData.ts               # Mock sessions (12)
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ utils.ts                  # UI utilities
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ timelineSearch.ts         # Search functionality
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ upload/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx             # Upload page
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ FileUploader.tsx           # File input
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ UploadProgress.tsx         # Progress bar
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ResultsView.tsx            # Results display
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useMoodAnalysis.ts            # Mood data hook
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useProgressMetrics.ts         # Progress metrics
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useConsistencyData.ts         # Consistency metrics
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ contexts/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ SessionDataContext.tsx        # Session state context
‚îÇ   ‚îî‚îÄ‚îÄ ask-ai/
‚îÇ       ‚îî‚îÄ‚îÄ page.tsx                 # Chat interface
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îú‚îÄ‚îÄ supabase.ts                  # Supabase client + types
‚îÇ   ‚îú‚îÄ‚îÄ api-client.ts                # Authenticated API client
‚îÇ   ‚îú‚îÄ‚îÄ api-types.ts                 # API type definitions
‚îÇ   ‚îú‚îÄ‚îÄ token-storage.ts             # Token management
‚îÇ   ‚îú‚îÄ‚îÄ demo-token-storage.ts        # Demo mode tokens
‚îÇ   ‚îú‚îÄ‚îÄ env-validation.ts            # Environment validation
‚îÇ   ‚îú‚îÄ‚îÄ dobby-system-prompt.ts       # AI chat system prompt
‚îÇ   ‚îú‚îÄ‚îÄ speaker-role-detection.ts    # Speaker identification
‚îÇ   ‚îú‚îÄ‚îÄ chat-context.ts              # AI context enrichment
‚îÇ   ‚îî‚îÄ‚îÄ types.ts                     # Global types
‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îú‚îÄ‚îÄ use-processing-status.ts     # Processing status polling
‚îÇ   ‚îú‚îÄ‚îÄ use-conversation-messages.ts # Chat messages
‚îÇ   ‚îî‚îÄ‚îÄ [30+ other hooks]
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ NavigationBar.tsx            # Top navigation
‚îÇ   ‚îú‚îÄ‚îÄ error-boundary.tsx           # Error handling
‚îÇ   ‚îú‚îÄ‚îÄ MarkdownMessage.tsx          # Markdown rendering
‚îÇ   ‚îî‚îÄ‚îÄ [many UI components]
‚îú‚îÄ‚îÄ contexts/
‚îÇ   ‚îú‚îÄ‚îÄ AuthContext.tsx              # Auth state
‚îÇ   ‚îî‚îÄ‚îÄ ProcessingContext.tsx        # Processing notifications
‚îî‚îÄ‚îÄ package.json
```

### Key Pages

#### 1. Patient Dashboard (dashboard-v3)
**File:** `app/patient/dashboard-v3/page.tsx`

**Components:**
- `SessionCardsGrid` - Displays 12 mock sessions in 4x3 grid
- `SessionCard` - Individual card with mood, topics, actions
- `TimelineSidebar` - Chronological view with search
- `ProgressPatternsCard` - Mood/topic trends visualization
- `NotesGoalsCard` - Treatment goals display
- `ToDoCard` - Actionable next steps

**Data Flow:**
1. `usePatientSessions()` hook loads mock data (or real API if enabled)
2. Sessions rendered in cards
3. Click session ‚Üí opens expanded modal
4. Timeline sidebar for date navigation
5. Trend analysis shows improving/declining patterns

#### 2. Upload Page
**File:** `app/patient/upload/page.tsx`

**Flow:**
1. Drag-drop audio file
2. `FileUploader` validates file type
3. `POST /api/upload` ‚Üí Supabase Storage
4. Session record created in DB
5. `POST /api/process` triggered
6. `UploadProgress` polls status every 2 seconds
7. When complete: dashboard refreshes automatically

#### 3. AI Chat (Dobby)
**File:** `app/ask-ai/page.tsx`

**Features:**
- Context-injected conversation
- Mood trends analysis
- Technique memory
- Goal progress indicators
- Crisis detection
- Session history integration

### Key Hooks

#### usePatientSessions
**File:** `app/patient/lib/usePatientSessions.ts`

```typescript
const {
  sessions,      // Session[]
  tasks,         // Task[]
  unifiedTimeline, // TimelineEvent[] (mixed sessions + events)
  majorEvents,   // MajorEventEntry[]
  isLoading,     // boolean
  refresh        // () => void
} = usePatientSessions();
```

**Features:**
- Toggle between mock data and real API
- Simulated network delay (300ms)
- Fallback to mock if API fails

#### useProcessingStatus
**File:** `hooks/use-processing-status.ts`

```typescript
const {
  status,           // 'pending' | 'processing' | 'completed' | 'failed'
  progress,         // 0-100
  estimatedTime,    // remaining seconds
  isComplete        // boolean
} = useProcessingStatus(sessionId);
```

**Features:**
- Polls `/api/status/{sessionId}` every 2 seconds
- Auto-stops when complete
- Exponential backoff on error

#### useMoodAnalysis
**File:** `app/patient/hooks/useMoodAnalysis.ts`

```typescript
const {
  moodHistory,      // Array of { date, score, trend }
  trend,            // 'improving' | 'stable' | 'declining'
  isLoading,        // boolean
} = useMoodAnalysis(patientId);
```

### Type Definitions

**Core Types:** `app/patient/lib/types.ts`

```typescript
interface Session {
  id: string;
  date: string;
  mood: MoodType;           // 'positive' | 'neutral' | 'low'
  topics: string[];         // AI-extracted topics
  strategy: string;         // Primary technique
  actions: string[];        // Action items
  summary?: string;         // AI summary (max 150 chars)
  deep_analysis?: DeepAnalysis;  // Wave 2 results
}

interface DeepAnalysis {
  progress_indicators: ProgressIndicator;
  therapeutic_insights: TherapeuticInsights;
  coping_skills: CopingSkills;
  therapeutic_relationship: TherapeuticRelationship;
  recommendations: Recommendations;
}
```

---

## Audio Pipeline

### Purpose
Convert raw audio files to transcribed, diarized, role-labeled segments.

### Flow

```
Audio File (MP3/WAV/M4A)
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Audio Preprocessing      ‚îÇ
‚îÇ - Load & validate           ‚îÇ
‚îÇ - Trim silence              ‚îÇ
‚îÇ - Normalize volume          ‚îÇ
‚îÇ - Convert to WAV (16kHz)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Transcription            ‚îÇ
‚îÇ - OpenAI Whisper API        ‚îÇ
‚îÇ - Or: faster-whisper (GPU)  ‚îÇ
‚îÇ - Output: timestamped text  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Speaker Diarization      ‚îÇ
‚îÇ - pyannote.audio 3.1        ‚îÇ
‚îÇ - Identifies SPEAKER_00,    ‚îÇ
‚îÇ   SPEAKER_01, etc.          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Speaker Role Detection   ‚îÇ
‚îÇ - First-speaker heuristic   ‚îÇ
‚îÇ - Speaking ratio heuristic  ‚îÇ
‚îÇ - Assigns Therapist/Client  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
JSON Transcript
[
  {
    "speaker": "Therapist",
    "text": "How are you feeling today?",
    "start": 0.0,
    "end": 2.5
  },
  ...
]
```

### Two Implementations

#### CPU/API Version (Production)
**File:** `src/pipeline.py`

- Uses OpenAI Whisper API (requires internet + API key)
- Speed: 5-7 minutes for 23-minute session
- Cost: ~$0.02 per session
- Works anywhere, no GPU needed

#### GPU Version (Research)
**File:** `src/pipeline_gpu.py`

- Uses faster-whisper locally on GPU
- Speed: 1.5 minutes for 23-minute session (10-15x realtime)
- Cost: Only Vast.ai/cloud instance fees
- Requires 16+ GB VRAM, CUDA 12.1

### Key Classes

#### AudioPreprocessor
```python
processor = AudioPreprocessor()
audio = processor.load_audio("session.mp3")
audio = processor.trim_silence(audio)
audio = processor.normalize_volume(audio)
```

#### WhisperTranscriber
```python
transcriber = WhisperTranscriber(api_key)
transcript = transcriber.transcribe(audio)
# Returns: List[Dict] with text, start, end
```

#### SpeakerDiarizer
```python
diarizer = SpeakerDiarizer(hf_token)
diarization = diarizer.diarize(audio)
# Returns: Annotation with speaker labels
```

---

## Data Flow

### Complete Audio Upload ‚Üí Display Pipeline

```
STEP 1: USER UPLOADS AUDIO
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend: app/patient/upload/page.tsx   ‚îÇ
‚îÇ - Drag-drop audio file                  ‚îÇ
‚îÇ - Select therapist from dropdown        ‚îÇ
‚îÇ - Click "Upload"                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
        POST /api/upload
        (FormData: file, patient_id, therapist_id)
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend: app/api/upload/route.ts       ‚îÇ
‚îÇ - Validate file type                    ‚îÇ
‚îÇ - Generate unique filename              ‚îÇ
‚îÇ - Upload to Supabase Storage            ‚îÇ
‚îÇ - Create therapy_sessions record (DB)   ‚îÇ
‚îÇ - Return: session_id, file_url          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
STEP 2: PROCESS AUDIO
        Frontend: FileUploader.tsx
        - Show "Upload complete" message
        - Display processing status
        - Start polling /api/status/{session_id}

        POST /api/process
        (JSON: { session_id })
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend: app/api/process/route.ts      ‚îÇ
‚îÇ - Get session from DB                   ‚îÇ
‚îÇ - Download audio from Supabase Storage  ‚îÇ
‚îÇ - Call BACKEND at http://localhost:8000‚îÇ
‚îÇ   (for REAL pyannote diarization)       ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ OR: Use mock diarization (if backend    ‚îÇ
‚îÇ     not running)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ BACKEND: app/api/transcribe (FastAPI)   ‚îÇ
‚îÇ - Receive audio file                     ‚îÇ
‚îÇ - Run Whisper transcription              ‚îÇ
‚îÇ - Run pyannote diarization               ‚îÇ
‚îÇ - Detect speaker roles (Therapist/Client)
‚îÇ - Return diarized + role-labeled trans.  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
STEP 3: STORE TRANSCRIPT
        Frontend: app/api/process/route.ts
        - Receive labeled transcript
        - Update therapy_sessions.transcript
        - Set processing_status = "completed"
        - Return session data to client
               ‚îÇ
               ‚ñº
STEP 4: TRIGGER ANALYSIS
        Backend: analyze_session_full_pipeline()
        
        WAVE 1 (Immediate):
        ‚îú‚îÄ Topic Extractor: topics, action_items, technique, summary
        ‚îú‚îÄ Mood Analyzer: mood_score, confidence, indicators
        ‚îî‚îÄ Update DB: wave1_analyzed_at, analysis data
        
        WAVE 2 (Async background task):
        ‚îú‚îÄ Deep Analyzer: progress, insights, skills, relationship
        ‚îú‚îÄ Prose Generator: narrative prose
        ‚îú‚îÄ Breakthrough Detector: breakthrough moments
        ‚îî‚îÄ Update DB: wave2_analyzed_at, deep_analysis data
               ‚îÇ
               ‚ñº
STEP 5: DISPLAY ON DASHBOARD
        Frontend: dashboard-v3/page.tsx
        - Load sessions via usePatientSessions()
        - Display SessionCards with:
          ‚îú‚îÄ Mood indicator (green/blue/rose)
          ‚îú‚îÄ Topics (from Wave 1)
          ‚îú‚îÄ Strategy (technique)
          ‚îú‚îÄ Action items
          ‚îî‚îÄ Deep analysis (Wave 2)
        - Display ProgressPatternsCard with:
          ‚îú‚îÄ Mood trend (improving/stable/declining)
          ‚îú‚îÄ Topic frequency chart
          ‚îî‚îÄ Technique usage history
```

### Database Schema (Key Tables)

```sql
-- Users & Patients
users:
  id UUID (PK)
  email VARCHAR
  first_name VARCHAR
  last_name VARCHAR
  role ('therapist' | 'patient')
  created_at TIMESTAMP

-- Therapy Sessions
therapy_sessions:
  id UUID (PK)
  patient_id UUID (FK users.id)
  therapist_id UUID (FK users.id)
  session_date TIMESTAMP
  duration_minutes INT
  
  -- Audio Processing
  audio_file_url VARCHAR
  processing_status VARCHAR ('pending' | 'processing' | 'completed' | 'failed')
  processing_progress INT (0-100)
  
  -- Transcription Results
  transcript JSONB  -- [{speaker, text, start, end}]
  
  -- Wave 1 Analysis (Immediate)
  topics TEXT[]  -- AI-extracted topics
  action_items TEXT[]  -- AI-extracted action items
  technique VARCHAR  -- Primary therapeutic technique
  summary TEXT  -- Ultra-brief summary (max 150 chars)
  mood_score FLOAT (0.0-10.0)
  mood_confidence FLOAT (0.0-1.0)
  mood_indicators TEXT[]
  emotional_tone VARCHAR
  wave1_analyzed_at TIMESTAMP
  
  -- Wave 2 Analysis (Async)
  deep_analysis JSONB  -- {progress_indicators, insights, coping_skills, ...}
  wave2_analyzed_at TIMESTAMP
  
  -- Breakthrough Detection
  has_breakthrough BOOLEAN
  breakthrough_data JSONB
  breakthrough_analyzed_at TIMESTAMP
  
  created_at TIMESTAMP
  updated_at TIMESTAMP

-- Session Transcripts (detailed)
session_transcripts:
  id UUID (PK)
  session_id UUID (FK therapy_sessions.id)
  speaker VARCHAR ('Therapist' | 'Client')
  text TEXT
  start_time FLOAT
  end_time FLOAT
  created_at TIMESTAMP

-- Session Notes (clinical)
session_notes:
  id UUID (PK)
  session_id UUID (FK therapy_sessions.id)
  therapist_id UUID (FK users.id)
  subjective TEXT
  objective TEXT
  assessment TEXT
  plan TEXT
  created_by VARCHAR ('ai' | 'therapist')
  created_at TIMESTAMP
  updated_at TIMESTAMP

-- Treatment Goals
treatment_goals:
  id UUID (PK)
  patient_id UUID (FK users.id)
  title VARCHAR
  description TEXT
  target_date DATE
  status VARCHAR ('active' | 'completed' | 'paused')
  progress INT (0-100)
  created_at TIMESTAMP
  updated_at TIMESTAMP

-- Breakthrough History
breakthrough_history:
  id UUID (PK)
  session_id UUID (FK therapy_sessions.id)
  breakthrough_type VARCHAR
  description TEXT
  evidence TEXT
  confidence_score FLOAT
  timestamp_start FLOAT
  timestamp_end FLOAT
  dialogue_excerpt JSONB
  is_primary BOOLEAN
  created_at TIMESTAMP

-- Mood Trends (for visualization)
patient_mood_trends:
  -- View: Rolling 7-day, 30-day, 90-day mood averages
  patient_id UUID
  period VARCHAR ('7_day' | '30_day' | '90_day')
  avg_mood FLOAT
  trend VARCHAR ('improving' | 'stable' | 'declining')
```

---

## Key Integration Points

### 1. Audio Upload ‚Üí Processing

**Frontend:**
```typescript
// app/patient/upload/page.tsx
const handleUpload = async (file: File) => {
  // 1. Upload file to Supabase Storage
  const uploadResponse = await fetch('/api/upload', {
    method: 'POST',
    body: formData,  // includes file, patient_id, therapist_id
  });
  
  const { session_id } = await uploadResponse.json();
  
  // 2. Trigger processing
  const processResponse = await fetch('/api/process', {
    method: 'POST',
    body: JSON.stringify({ session_id }),
  });
  
  // 3. Poll status
  useProcessingStatus(session_id);  // Polls every 2 seconds
};
```

**Backend:**
```python
# app/routers/sessions.py
@router.post("/upload-transcript")
async def upload_transcript(session_id, data, background_tasks):
    # 1. Store transcript
    db.table("therapy_sessions").update({
        "transcript": data.transcript,
        "processing_status": "completed"
    }).eq("id", session_id).execute()
    
    # 2. Trigger Wave 1 analysis immediately
    # 3. Queue Wave 2 for background processing
    background_tasks.add_task(
        analyze_session_full_pipeline,
        session_id,
        data.transcript
    )
```

### 2. Analysis Results ‚Üí Database

**Backend Service:**
```python
# app/services/mood_analyzer.py
class MoodAnalyzer:
    def analyze_session(self, transcript):
        # Call GPT-4o-mini
        response = openai.ChatCompletion.create(...)
        
        return MoodAnalysis(
            mood_score=extracted_score,  # 0.0-10.0
            confidence=confidence,
            rationale=rationale,
            key_indicators=indicators
        )
```

**Router Integration:**
```python
# app/routers/sessions.py
@router.post("/{session_id}/analyze-mood")
async def analyze_mood_endpoint(session_id):
    # 1. Get transcript
    session = db.table("therapy_sessions").select("transcript").eq("id", session_id).single().execute()
    
    # 2. Run mood analysis
    analyzer = MoodAnalyzer(api_key)
    mood = analyzer.analyze_session(session["transcript"])
    
    # 3. Store in database
    db.table("therapy_sessions").update({
        "mood_score": mood.mood_score,
        "mood_confidence": mood.confidence,
        "mood_indicators": mood.key_indicators,
        "emotional_tone": mood.emotional_tone,
        "wave1_analyzed_at": datetime.now()
    }).eq("id", session_id).execute()
    
    return mood
```

### 3. Mock Data ‚Üí Real Data Toggle

**Frontend Hook:**
```typescript
// app/patient/lib/usePatientSessions.ts
const USE_MOCK_DATA = true;  // Set to false for real API

export function usePatientSessions() {
  useEffect(() => {
    if (USE_MOCK_DATA) {
      // Use mock sessions (12 predefined)
      setSessions(mockSessions);
    } else {
      // Call real API
      const result = await apiClient.get(
        `/api/sessions/patient/${patientId}`
      );
      setSessions(result.data.sessions);
    }
  }, []);
}
```

### 4. Demo Mode Flow

**Step 1: Initialize**
```typescript
// Frontend
const demoResponse = await fetch('/api/demo/init', {
  method: 'POST'
});

const { demo_token, patient_id, session_ids } = await demoResponse.json();
demoTokenStorage.save(demo_token, patient_id);
```

**Step 2: Backend Creates Sessions**
```python
# app/routers/demo.py
@router.post("/init")
async def init_demo(db: Client = Depends(get_db)):
    # 1. Create demo patient
    patient = db.table("users").insert({
        "email": "demo@example.com",
        "role": "patient"
    }).execute()
    
    # 2. Create 12 mock sessions
    sessions = []
    for i in range(12):
        session = db.table("therapy_sessions").insert({
            "patient_id": patient["id"],
            "session_date": generate_date(i),
            "transcript": MOCK_TRANSCRIPTS[i],
            "processing_status": "completed"
        }).execute()
        sessions.append(session)
    
    # 3. Trigger Wave 1 analysis for all
    background_tasks.add_task(
        run_wave1_analysis_background,
        patient["id"]
    )
    
    # 4. Queue Wave 2 analysis
    background_tasks.add_task(
        run_wave2_analysis_background,
        patient["id"]
    )
```

### 5. AI Chat Context Injection

**System Prompt Injection:**
```typescript
// lib/chat-context.ts
const enrichContext = async (patientId: string) => {
  // Fetch mood trends
  const moodHistory = await fetch(`/api/sessions/patient/${patientId}/mood-history`);
  
  // Fetch recent breakthroughs
  const breakthroughs = await fetch(`/api/sessions/patient/${patientId}/breakthroughs`);
  
  // Fetch goal progress
  const goals = await fetch(`/api/patient/${patientId}/goals`);
  
  // Build context string
  const context = `
    Recent mood trend: ${calculateTrend(moodHistory)}
    Recent techniques: ${extractTechniques(breakthroughs)}
    Goal progress: ${formatGoals(goals)}
  `;
  
  return context;
};

// Inject into system prompt
const systemPrompt = `${DOBBY_BASE_PROMPT}\n\nContext:\n${context}`;
```

---

## Current Implementation Status

### COMPLETE ‚úÖ

**Backend:**
- [x] FastAPI application structure
- [x] Supabase integration
- [x] Session CRUD endpoints
- [x] Mood analyzer service (GPT-4o-mini)
- [x] Topic extractor service (GPT-4o-mini)
- [x] Breakthrough detector service (GPT-4o-mini)
- [x] Deep analyzer service (Wave 2)
- [x] Speaker labeler service
- [x] Analysis orchestrator
- [x] Progress metrics extraction
- [x] Demo mode endpoints
- [x] Authenticated API client (frontend)

**Frontend:**
- [x] Next.js 16 + React 19 setup
- [x] Dashboard V3 with session cards
- [x] Session card components
- [x] Upload page
- [x] Processing status polling
- [x] Timeline visualization
- [x] Major event modal
- [x] Mood trend visualization
- [x] Export functionality (PDF)
- [x] Mock data system (12 sessions)

**Audio Pipeline:**
- [x] Audio preprocessing (trim silence, normalize)
- [x] Whisper transcription (API)
- [x] pyannote diarization (3.1)
- [x] Speaker role detection

### PARTIAL / IN PROGRESS üîÑ

**Backend:**
- [ ] Full authentication system (using demo mode)
- [ ] Email notifications
- [ ] Session search/filtering

**Frontend:**
- [ ] Real API integration (toggle available, not fully tested)
- [ ] Therapist dashboard (patient view exists)
- [ ] Session editing/deletion
- [ ] Note taking interface

**Audio Pipeline:**
- [ ] GPU version (Vast.ai) - documented but not tested
- [ ] Background job processing (manual triggering works)

### NOT STARTED ‚è≥

**Backend:**
- [ ] Session deletion cascade
- [ ] Semantic search (pgvector)
- [ ] Real-time WebSocket updates
- [ ] File upload to S3

**Frontend:**
- [ ] Therapist note-taking
- [ ] Patient goal management
- [ ] Subscription/billing
- [ ] Mobile responsive design

---

## Critical Files Reference

### Must-Know Backend Files

| File | Purpose | Lines | Status |
|------|---------|-------|--------|
| `app/main.py` | FastAPI app entry point | 89 | ‚úÖ Complete |
| `app/config.py` | Environment configuration | 84 | ‚úÖ Complete |
| `app/database.py` | Supabase client + helpers | 201 | ‚úÖ Complete |
| `app/routers/sessions.py` | Session endpoints | 700+ | ‚úÖ Complete |
| `app/routers/demo.py` | Demo mode endpoints | 300+ | ‚úÖ Complete |
| `app/services/breakthrough_detector.py` | AI breakthrough detection | 300+ | ‚úÖ Complete |
| `app/services/mood_analyzer.py` | AI mood analysis | 200+ | ‚úÖ Complete |
| `app/services/topic_extractor.py` | AI topic extraction | 250+ | ‚úÖ Complete |
| `app/services/deep_analyzer.py` | Wave 2 clinical analysis | 500+ | ‚úÖ Complete |
| `app/services/speaker_labeler.py` | Therapist/Client detection | 250+ | ‚úÖ Complete |
| `app/services/analysis_orchestrator.py` | Analysis coordination | 400+ | ‚úÖ Complete |

### Must-Know Frontend Files

| File | Purpose | Status |
|------|---------|--------|
| `app/patient/dashboard-v3/page.tsx` | Main dashboard | ‚úÖ Complete |
| `app/patient/dashboard-v3/components/SessionCardsGrid.tsx` | Session grid | ‚úÖ Complete |
| `app/patient/dashboard-v3/components/SessionCard.tsx` | Individual card | ‚úÖ Complete |
| `app/patient/lib/usePatientSessions.ts` | Session data hook | ‚úÖ Complete |
| `app/patient/lib/mockData.ts` | 12 mock sessions | ‚úÖ Complete |
| `app/api/upload/route.ts` | File upload endpoint | ‚úÖ Complete |
| `app/api/process/route.ts` | Audio processing | ‚úÖ Complete |
| `app/api/status/[sessionId]/route.ts` | Status polling | ‚úÖ Complete |
| `lib/api-client.ts` | Authenticated API client | ‚úÖ Complete |
| `lib/supabase.ts` | Supabase client + types | ‚úÖ Complete |
| `lib/dobby-system-prompt.ts` | AI chat system prompt | ‚úÖ Complete |
| `lib/speaker-role-detection.ts` | Speaker identification | ‚úÖ Complete |

### Must-Know Configuration Files

| File | Purpose | Status |
|------|---------|--------|
| `backend/.env` | Backend secrets (complete) | ‚úÖ Configured |
| `frontend/.env.local` | Frontend config | ‚úÖ Configured |
| `audio-transcription-pipeline/.env` | Pipeline config | ‚úÖ Configured |
| `.python-version` | Python version (root, backend) | ‚úÖ 3.13.9 |
| `backend/requirements.txt` | Python dependencies | ‚úÖ Complete |
| `frontend/package.json` | Node dependencies | ‚úÖ Complete |

---

## Development Workflow

### To Add a New Backend Service

1. Create file: `app/services/my_service.py`
2. Implement service class with `__init__` and analysis method
3. Add response model to `app/routers/sessions.py`
4. Add endpoint to sessions router
5. Test with `pytest` or manual `curl` request
6. Document in this file

### To Add a New Frontend Component

1. Create component in appropriate folder
2. Import types from `app/patient/lib/types.ts`
3. Use `usePatientSessions()` or other hooks for data
4. Add to appropriate page or card
5. Test with mock data first
6. Enable real API when ready

### To Deploy

**Backend (FastAPI):**
```bash
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn app.main:app --reload
```

**Frontend (Next.js):**
```bash
cd frontend
npm install
npm run dev
```

**Audio Pipeline:**
```bash
cd audio-transcription-pipeline
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python tests/test_full_pipeline.py
```

---

## Troubleshooting

### Backend not responding
- Check if FastAPI is running: `ps aux | grep uvicorn`
- Verify Supabase URL and keys in `.env`
- Check CORS settings in `app/main.py`

### Audio processing fails
- Verify OpenAI API key is set
- Check audio file format (MP3, WAV, M4A supported)
- Ensure pyannote models are cached (~1GB)

### Frontend shows "Connection refused"
- Start backend first (`uvicorn app.main:app --reload`)
- Check `API_BASE_URL` in `lib/api-client.ts` (default: localhost:8000)
- Verify CORS allows frontend origin

### Wave 2 analysis slow
- Deep analysis can take 1-2 minutes
- Check backend logs for API rate limits
- Wave 2 runs asynchronously after Wave 1

---

## Next Steps

1. **Real API Integration Test**
   - Set `USE_MOCK_DATA = false` in `usePatientSessions.ts`
   - Verify all sessions load from backend
   - Test with real session data

2. **End-to-End Testing**
   - Upload real audio file
   - Verify transcription works
   - Confirm all analysis waves complete
   - Check results display on dashboard

3. **Performance Optimization**
   - Implement session pagination
   - Add caching for frequently-accessed data
   - Optimize database queries with proper indexes

4. **Feature Completion**
   - Implement therapist dashboard
   - Add session note-taking
   - Build goal management interface
   - Add semantic search

---

## Document History

- **2025-12-27**: Initial comprehensive architecture map created
- **Status**: Current to git commit `227586b`
- **Coverage**: All 3 systems (backend, frontend, audio pipeline)

