---
description: Orchestrate complex tasks using intelligent parallel execution
---

# Parallel Task Orchestration

You are executing a parallel orchestration command. When invoked with `/cl:orchestrate [task]`, you MUST follow this protocol:

## ğŸ“š Reference Documentation

**IMPORTANT: Read these files for complete methodology before executing:**

1. **`.claude/DYNAMIC_WAVE_ORCHESTRATION.md`** - Contains:
   - Intelligent auto-scaling algorithm (how to calculate optimal agent count)
   - Task type classification (file_operations, api_calls, deployment, etc.)
   - ROI analysis methodology
   - Extreme scaling scenarios and examples

2. **`.claude/agents/cl/parallel-orchestrator.md`** - Contains:
   - Complete execution protocol
   - Task decomposition methodology (how to break tasks into subtasks)
   - Dependency analysis (how to build DAG)
   - Wave generation rules (how to organize tasks into waves)
   - Tool usage guidelines

**Use these files to inform your decisions when calculating agent counts and structuring waves.**

---

## STEP 1: Wave 0 - Deep Analysis Using Parallel Research Agents (REQUIRED)

**ğŸš¨ CRITICAL: Launch parallel research agents BEFORE planning execution waves.**

**DO NOT use surface-level tool calls (Grep/Glob/Read).** Instead, launch specialized parallel agents to conduct deep research.

### Step 1a: Parse User Request

Extract:
- Task description
- Explicit agent count (if user says "using X agents") - MUST honor exactly if specified
- Target files/directories

### Step 1b: Identify Research Needs

Determine what research is required:
- File discovery? â†’ Use `codebase-locator`
- Implementation analysis? â†’ Use `codebase-analyzer`
- Pattern discovery? â†’ Use `codebase-pattern-finder`
- Architecture understanding? â†’ Use `Explore` (very thorough)
- Best practices? â†’ Use `web-search-researcher`

### Step 1c: Launch Wave 0 Research Agents (In Parallel)

**Output format:**
```
ğŸ” ANALYZING TASK...

Task: [user's task]

ğŸ“‹ RESEARCH REQUIREMENTS IDENTIFIED:
- [Research need 1] (agent type)
- [Research need 2] (agent type)
- [Research need 3] (agent type)

ğŸŒŠ WAVE 0: PARALLEL RESEARCH ([N] agents launching...)

Launching [N] specialized research agents in parallel:
â”œâ”€ Agent R1 ([agent-type]): [Research task 1]
â”œâ”€ Agent R2 ([agent-type]): [Research task 2]
â””â”€ Agent R[N] ([agent-type]): [Research task N]
```

**Then ACTUALLY LAUNCH the agents using multiple Task tool calls in ONE message:**
```xml
<function_calls>
<invoke name="Task">
<parameter name="subagent_type">codebase-locator</parameter>
<parameter name="description">Wave 0.1: Locate relevant files</parameter>
<parameter name="prompt">Find all files and components relevant to: [task]</parameter>
</invoke>
<invoke name="Task">
<parameter name="subagent_type">codebase-analyzer</parameter>
<parameter name="description">Wave 0.2: Analyze implementation</parameter>
<parameter name="prompt">Analyze implementation details for: [task]</parameter>
</invoke>
... (additional research agents)
</function_calls>
```

### Step 1d: Aggregate Research Findings

**After Wave 0 completes, output:**
```
â³ Waiting for Wave 0 research to complete...

âœ… WAVE 0 COMPLETE - Research Findings:

Agent R1 ([agent-type]) found:
- [Specific finding with details]
- [Specific finding with details]

Agent R2 ([agent-type]) discovered:
- [Specific finding with details]

... (all research findings)

ğŸ“Š PLANNING EXECUTION WAVES...

Based on research findings:
SUBTASKS IDENTIFIED: [count]
â”œâ”€ [Subtask 1]
â”œâ”€ [Subtask 2]
â”œâ”€ [Subtask 3]
â””â”€ ...

DEPENDENCIES: [None/Shallow/Deep]
TASK TYPE: [file_operations/api_calls/deployment/code_analysis/general]
AVG DURATION: [X] minutes per subtask

SCALING DECISION:
â”œâ”€ System calculated optimal: [N] agents
â”œâ”€ User requested: [X] agents (if specified, otherwise "auto")
â”œâ”€ Resource capacity: [Max] agents
â””â”€ Decision: USING [X] AGENTS [reason]
```

**If user specified agent count:**
```
SCALING DECISION:
â”œâ”€ User requested: [X] agents ğŸ¯
â”œâ”€ System calculated optimal: [N] agents
â””â”€ Decision: USING [X] AGENTS (user override - honored exactly) âœ…
```

## STEP 1.5: Git Backup (REQUIRED)

**ğŸš¨ CRITICAL: Before ANY execution, create a git backup commit per CLAUDE.md rules.**

After Wave 0 research completes and before showing wave structure:

```
ğŸ”’ GIT BACKUP (Required by CLAUDE.md):

Checking git status...
Creating safety backup before orchestration...

Commands:
1. git status
2. git add -A
3. git commit -m "Backup before orchestration: [task description]"
4. git log -1

âœ… Backup commit created: [commit hash]

This ensures all work (tracked and untracked) is preserved before changes.
```

**Execute these git commands using Bash tool:**
```xml
<invoke name="Bash">
<parameter name="command">cd [project_root] && git add -A && git commit -m "Backup before orchestration: [task]" && git log -1 --oneline</parameter>
<parameter name="description">Create git backup commit</parameter>
</invoke>
```

**Why this is required:**
- Per CLAUDE.md: "BEFORE MAKING ANY CHANGES (deletions, modifications, cleanup)"
- Orchestration will modify/create/delete files
- Untracked files CANNOT be recovered without a commit
- Creates safety net for ALL files (tracked and untracked)

---

## STEP 2: Output Wave Structure (REQUIRED)

**ğŸš¨ CRITICAL: Show POOL SIZE (maximum across waves), not total agent slots.**

```
ğŸŒŠ WAVE STRUCTURE:

Wave 1: [Description] ([N] agents)
â”œâ”€ Agent 1.1: [task]
â”œâ”€ Agent 1.2: [task]
â””â”€ ...

Wave 2: [Description] ([M] agents)
â””â”€ ...

Wave 3: [Description] ([P] agents - reusing from pool)
â””â”€ ...

ğŸŠ AGENT POOL SUMMARY:
â”œâ”€ Pool size: [MAX] agents (maximum needed across all waves)
â”œâ”€ Total waves: [W]
â”œâ”€ Wave requirements: W1=[N], W2=[M], W3=[P], ...
â”œâ”€ Total agent slots: [N+M+P+...] (if creating new agents each wave)
â”œâ”€ With pooling: [MAX] agents created
â”œâ”€ Agent reuse rate: [X]%
â””â”€ Efficiency: [Y]% fewer agents needed

Estimated: [X] min vs [Y] min sequential
Speedup: [Z]% faster
```

**Example (CORRECT):**
```
ğŸŒŠ WAVE STRUCTURE:

Wave 1: Database Schema (3 agents)
â”œâ”€ I1 (Database Engineer #1): Create analytics models
â”œâ”€ I2 (Database Engineer #2): Create Alembic migration
â””â”€ I3 (Database Engineer #3): Create Pydantic schemas

Wave 2: Backend Implementation (6 agents)
â”œâ”€ I1 (Backend Dev #1): Analytics service - overview â™»ï¸ REUSED
â”œâ”€ I2 (Backend Dev #2): Analytics service - patient progress â™»ï¸ REUSED
â”œâ”€ I3 (Backend Dev #3): Analytics service - session trends â™»ï¸ REUSED
â”œâ”€ I4 (Backend Dev #4): Analytics service - topics ğŸ†• NEW
â”œâ”€ I5 (API Developer #1): Router with /overview endpoint ğŸ†• NEW
â””â”€ I6 (API Developer #2): Router with patient/trends/topics endpoints ğŸ†• NEW

Wave 3: Scheduler Infrastructure (3 agents - reusing from pool)
â”œâ”€ I1 (DevOps Engineer): APScheduler setup â™»ï¸ REUSED
â”œâ”€ I2 (Backend Dev #5): Background tasks module â™»ï¸ REUSED
â””â”€ I3 (Backend Dev #6): Integrate scheduler with lifespan â™»ï¸ REUSED

Wave 4: Testing & Validation (6 agents - reusing from pool)
â”œâ”€ I1-I6 all reused â™»ï¸

Wave 5: Integration (2 agents - reusing from pool)
â”œâ”€ I1, I2 reused â™»ï¸

ğŸŠ AGENT POOL SUMMARY:
â”œâ”€ Pool size: 6 agents (maximum needed in Wave 2)
â”œâ”€ Total waves: 5
â”œâ”€ Wave requirements: W1=3, W2=6, W3=3, W4=6, W5=2
â”œâ”€ Total agent slots: 20 (if creating new agents each wave)
â”œâ”€ With pooling: 6 agents created
â”œâ”€ Agent reuse rate: 70% (14 of 20 slots reuse existing agents)
â””â”€ Efficiency: 70% fewer agents needed

Estimated: 45 min vs 5 hours sequential
Speedup: 85% faster
```

## STEP 3: Initialize Agent Pool with Clear Roles (REQUIRED)

**ğŸš¨ CRITICAL: Create ALL agents upfront with descriptive roles. Reuse them across waves.**

### Agent Pool Strategy:

1. **Parse user request** - Check if explicit agent count specified
2. **Determine pool size using MAXIMUM strategy**:
   - **If user specified count**: Pool size = user-requested count (MUST honor exactly)
   - **If auto-scaling**: Pool size = MAXIMUM agents needed across ALL waves (not average, MAXIMUM)
   - **Goal**: Maximize agent reuse across multiple waves
   - **Example**: If Wave 1 needs 15 agents, Wave 2 needs 8, Wave 3 needs 12 â†’ Create 15-agent pool (not 8 or 12)
3. **Assign clear roles to each agent** based on tasks:
   - File operations â†’ "File Reader #1-N", "File Processor #1-N", "Consolidator"
   - Database â†’ "Database Analyst", "Migration Engineer #1-N", "Schema Validator"
   - Backend â†’ "Backend Dev #1-N", "API Developer #1-N", "Service Builder"
   - Frontend â†’ "Frontend Dev #1-N", "Component Engineer #1-N", "UI Specialist #1-N"
   - Testing â†’ "Test Engineer #1-N", "QA Validator #1-N", "Integration Tester"
   - Security â†’ "Security Engineer", "Audit Specialist", "Vulnerability Analyst"
   - DevOps â†’ "DevOps Engineer", "Deployment Specialist", "Infrastructure"
   - Documentation â†’ "Documentation Specialist", "README Writer"
4. **Create agent pool manifest** - Map each agent instance (I1, I2, etc.) to its role
5. **Initialize TodoWrite** - Include agent roles and wave assignments
6. **Execute waves** - Assign specific agents by role to tasks

**ğŸš¨ CRITICAL RULES:**
- **ALL agents created upfront** - No on-demand agent creation during execution
- **Clear descriptive roles** - Every agent has a specific job title
- **Agent persistence** - Same agent instances used across multiple waves
- **Role-based assignment** - Tasks assigned to agents by their role/expertise

### Execution Steps:

**Step 3a: Create Agent Pool Manifest (REQUIRED)**

Before executing any waves, create a manifest mapping agents to roles:

```
ğŸŠ AGENT POOL INITIALIZATION:

Creating pool of [N] agents with assigned roles:

| Instance | Role | Specialty | Waves Assigned |
|----------|------|-----------|----------------|
| I1 | Backend Dev #1 | API endpoints | W1, W3 |
| I2 | Backend Dev #2 | Services layer | W1, W3 |
| I3 | Frontend Dev #1 | Components | W2, W4 |
| I4 | Frontend Dev #2 | Hooks/utils | W2, W4 |
| I5 | Test Engineer #1 | Unit tests | W5 |
| I6 | Test Engineer #2 | Integration tests | W5 |
| I7 | Security Engineer | Auditing | W6 |
| I8 | Documentation Specialist | README/guides | W7 |
| ... | ... | ... | ... |

Pool Statistics:
â”œâ”€ Total agents: [N]
â”œâ”€ Total waves: [W]
â”œâ”€ Agent reuse rate: [X]% (Y agents work multiple waves)
â”œâ”€ Average tasks per agent: [Z]
â””â”€ Pool efficiency: [E]% âœ…
```

**Step 3b: Output Pool Strategy**

**Auto-scaling mode:**
```
ğŸŠ AGENT POOL STRATEGY:
â”œâ”€ Pool size: [N] agents (based on largest wave)
â”œâ”€ Total waves: [W]
â”œâ”€ Total agent slots: [X] (sum across all waves)
â”œâ”€ Without pooling: [X] agents created
â”œâ”€ With pooling: [N] agents created (reuse [Y]%)
â””â”€ Overhead saved: [Z]s â™»ï¸
```

**User-requested agent count:**
```
ğŸŠ AGENT POOL STRATEGY:
â”œâ”€ User requested: [X] agents ğŸ¯
â”œâ”€ Pool size: [X] agents (honoring user request exactly)
â”œâ”€ System optimal: [N] agents
â”œâ”€ Total waves: [W]
â”œâ”€ Decision: Creating pool of [X] agents as requested âœ…
â””â”€ Note: [More/Fewer] than optimal, but user preference honored
```

**Step 3c: Execute Wave 1 (Pool Initialization with Roles)**

```
ğŸŒŠ WAVE 1: [Description]
â”œâ”€ Agents needed: [N]
â”œâ”€ Pool status: Creating fresh pool of [N] agents with roles
â”œâ”€ Assignments:
â”‚   â”œâ”€ I1 (Backend Dev #1): [Specific task]
â”‚   â”œâ”€ I2 (Backend Dev #2): [Specific task]
â”‚   â”œâ”€ I3 (Frontend Dev #1): [Specific task]
â”‚   â””â”€ ... (N agents total)
â””â”€ Status: Launching [N] agents in parallel... ğŸ†•

[Launch N agents in parallel - ONE message with N Task calls]
[Each Task description includes: "Wave 1.X: [Role] - [Task description]"]
```

**ğŸš¨ CRITICAL: Agent roles MUST be in the prompt at launch, not just in description**

**Example Task invocations:**
```xml
<function_calls>
<invoke name="Task">
<parameter name="subagent_type">general-purpose</parameter>
<parameter name="description">Wave 1.1: Backend Dev #1 - Implement auth endpoint</parameter>
<parameter name="prompt">You are Backend Dev #1 (Instance I1) working on Wave 1.

Your role: Backend developer specializing in authentication endpoints
Your task: Implement the authentication endpoint at backend/app/routers/auth.py

Context: You are part of a 6-agent team implementing a full-stack feature. Your specialty is backend API development.

Requirements:
- Create POST /auth/login endpoint
- Validate email/password input
- Return JWT token on success
- Follow existing patterns in auth.py

Success criteria: Endpoint functional, follows project patterns, returns proper JWT token

When complete, report your deliverables with specific metrics (e.g., "Created /auth/login endpoint, 45 lines, JWT token generation with 24h expiry").</parameter>
</invoke>
<invoke name="Task">
<parameter name="subagent_type">general-purpose</parameter>
<parameter name="description">Wave 1.2: Backend Dev #2 - Implement session endpoint</parameter>
<parameter name="prompt">You are Backend Dev #2 (Instance I2) working on Wave 1.

Your role: Backend developer specializing in session management
Your task: Implement the session creation endpoint at backend/app/routers/sessions.py

Context: You are part of a 6-agent team. Backend Dev #1 is working on auth, you're handling sessions.

Requirements:
- Create POST /sessions/create endpoint
- Accept session data payload
- Store in database
- Return session ID

Success criteria: Endpoint functional, database integration working

When complete, report your deliverables with specific metrics.</parameter>
</invoke>
... (more agents with roles in prompts)
</function_calls>
```

**Step 3d: Execute Wave 2+ (Reuse Agents by Role)**

```
ğŸŒŠ WAVE [X]: [Description]
â”œâ”€ Agents needed: [M]
â”œâ”€ Pool status: [N] agents available for reuse
â”œâ”€ Assignments:
â”‚   â”œâ”€ I1 (Backend Dev #1): [New task] â™»ï¸ REUSED
â”‚   â”œâ”€ I3 (Frontend Dev #1): [New task] â™»ï¸ REUSED
â”‚   â””â”€ ... (M agents total)
â””â”€ Status: Assigning tasks to agents from pool...

[Assign tasks to M agents from pool by their roles]
[Tasks given to agents match their expertise/role]
```

**Step 3e: Execute All Remaining Waves**

Continue executing waves sequentially until all planned waves complete.

For each subsequent wave:
1. Output wave header with assignments
2. Launch agents in parallel (reusing from pool)
3. Wait for completion
4. Update TodoWrite
5. **Output context window usage** (see format below)
6. Move to next wave

**ğŸš¨ CRITICAL: After EVERY wave completion, show context window usage:**

```
âœ… WAVE [X] COMPLETE

ğŸ“Š CONTEXT WINDOW STATUS:
â”œâ”€ Main window: [X]K / 200K tokens ([Y]% used)
â”œâ”€ Remaining: [Z]K tokens
â””â”€ Status: [HEALTHY/WARNING/CRITICAL] âš ï¸

[If WARNING or CRITICAL, add this:]
ğŸ’¡ If context is running low, you can copy the continuation prompt above to continue in a new window.
```

**Status thresholds:**
- HEALTHY: < 150K tokens used (< 75%)
- WARNING: 150K-180K tokens used (75-90%) âš ï¸
- CRITICAL: > 180K tokens used (> 90%) ğŸš¨

**If wave needs MORE agents than pool capacity:**
```
ğŸŒŠ WAVE [X]: [Description]
â”œâ”€ Agents needed: [P]
â”œâ”€ Pool capacity: [N] agents
â”œâ”€ Reused agents: [N] â™»ï¸ (all from pool)
â”œâ”€ New agents: [P-N] ğŸ†• (expanding pool)
â””â”€ Pool expanded to: [P] agents

[Reuse all N from pool + create P-N new agents]
```

### Key Rules:

1. **Create pool once** - Based on maximum wave size
2. **Reuse agents** - Don't create new agents if pool has capacity
3. **Keep agents alive** - Don't destroy between waves
4. **Expand only when needed** - If wave exceeds pool capacity
5. **Track utilization** - Report which agents did multiple tasks

## STEP 4: Report Results and Continuation Prompt

**ğŸš¨ MANDATORY FORMAT: Use detailed agent tracking table with roles, waves, and deliverables.**

### Step 4a: Comprehensive Execution Summary

### Required Reporting Format:

```
## ğŸ“Š EXECUTION SUMMARY
### âœ… Agents Completed: [N]/[N]

| Instance | Role | Waves | Status | Key Deliverables |
|----------|------|-------|--------|------------------|
| I1 | [Role Name] | W[X] | âœ… COMPLETE | [Specific deliverable with metrics] |
| I2 | [Role Name] | W[X] | âœ… COMPLETE | [Specific deliverable with metrics] |
| I3 | [Role Name] | W[X]-W[Y] | âœ… COMPLETE | [Specific deliverable with metrics] |
| ... | ... | ... | ... | ... |

### ğŸ“ˆ Performance Metrics:
- **Total Waves Executed:** [W]
- **Execution Time:** [X] minutes
- **Sequential Time:** [Y] minutes
- **Time Saved:** [Z] minutes ([P]% faster)
- **Agent Reuse Rate:** [R]%
- **Pool Efficiency:** [E]%

### ğŸ“Š Context Window Usage:
- **Main window:** [X]K / 200K tokens ([Y]% used)
- **Remaining:** [Z]K tokens
- **Status:** [HEALTHY/WARNING/CRITICAL]
- **Agent windows:** Wave 0: [N] agents, Waves 1-[W]: [M] total agents launched

### ğŸ¯ Final Results:
[Detailed list of what was accomplished]
```

### Role Assignment Rules:

**Assign each agent a clear, descriptive role based on their task:**
- File operations â†’ "File Processor", "Reader", "Writer", "Consolidator"
- Database tasks â†’ "Database Analyst", "Migration Engineer", "Data Specialist"
- Backend work â†’ "Backend Dev #1", "API Developer", "Endpoint Engineer"
- Security â†’ "Security Engineer", "Audit Specialist"
- Testing â†’ "Test Engineer #1", "Integration Tester", "QA Validator"
- DevOps â†’ "DevOps", "Deployment Specialist", "CI/CD Engineer"
- Documentation â†’ "Documentation", "Doc Writer", "README Specialist"
- Coordination â†’ "Coordinator", "Orchestrator", "Backup Specialist"
- Code Review â†’ "Code Reviewer", "Security Auditor"
- Cleanup â†’ "Cleanup Specialist", "Maintenance Engineer"

### Wave Notation:

- Single wave: `W1`, `W2`, `W3`
- Multiple waves: `W1-W3`, `W2, W5`, `W1, W3-W5`
- Indicate if agent worked across multiple waves

### Deliverables Format:

**Be SPECIFIC with metrics:**
- âœ… "Schema analysis (users: 7 cols, auth_sessions: 6 cols)"
- âœ… "22 integration tests, pytest fixtures"
- âœ… "Security audit 9.5/10 - APPROVED for production"
- âœ… "Git backup (commit 3b2aa4e)"
- âŒ "Created tests" (too vague)
- âŒ "Updated documentation" (too vague)

**Example Report:**

```
## ğŸ“Š EXECUTION SUMMARY
### âœ… Agents Completed: 6/6

| Instance | Role | Waves | Status | Key Deliverables |
|----------|------|-------|--------|------------------|
| I1 | File Reader #1 | W1 | âœ… COMPLETE | Read SECURITY_ANALYSIS.md (11 KB, SQL injection findings) |
| I2 | File Reader #2 | W1 | âœ… COMPLETE | Read SECURITY_SUMMARY.txt (12 KB, compliance status) |
| I3 | File Reader #3 | W1 | âœ… COMPLETE | Read SECURITY_REPORT_INDEX.md (7.2 KB, navigation guide) |
| I4 | File Reader #4 | W1 | âœ… COMPLETE | Read VULNERABILITY_CHECKLIST.md (20+ components audited) |
| I5 | File Reader #5 | W1 | âœ… COMPLETE | Read SECURITY_FIX_PATCH.py (393 lines, remediation code) |
| I6 | File Reader #6 | W1 | âœ… COMPLETE | Read SECURITY_REPORT_EXECUTIVE_SUMMARY.txt (CVSS 8.6 findings) |
| I1 | Consolidator | W2 | âœ… COMPLETE | Created Security-Report.md (40 KB, 1,519 lines, 6 sources merged) |
| I2 | Cleanup Specialist | W3 | âœ… COMPLETE | Removed 6 scattered files, verified consolidation |

### ğŸ“ˆ Performance Metrics:
- **Total Waves Executed:** 3
- **Execution Time:** 6 minutes
- **Sequential Time:** 16 minutes
- **Time Saved:** 10 minutes (62% faster)
- **Agent Reuse Rate:** 25% (2 agents reused across waves)
- **Pool Efficiency:** 83%

### ğŸ¯ Final Results:
- âœ… Created comprehensive Security-Report.md (40 KB, 1,519 lines)
- âœ… Consolidated 6 security files into single authoritative source
- âœ… Eliminated redundancy while preserving all unique information
- âœ… Removed scattered files: SECURITY_ANALYSIS.md, SECURITY_SUMMARY.txt, SECURITY_REPORT_INDEX.md, VULNERABILITY_CHECKLIST.md, SECURITY_FIX_PATCH.py, SECURITY_REPORT_EXECUTIVE_SUMMARY.txt
```

---

### Step 4b: Provide Orchestration Continuation Prompt (REQUIRED)

**ğŸš¨ CRITICAL: After completing ALL waves and providing the execution summary, provide a continuation prompt for follow-up orchestration.**

After the execution summary, output:

```
---

ğŸ’¡ FOLLOW-UP ORCHESTRATION PROMPT:

If there are additional improvements or follow-up tasks to address, you can run:

/cl:orchestrate [describe the follow-up task]

Example follow-up tasks based on what was just completed:
- Further refinements or enhancements
- Testing and validation of changes
- Documentation updates
- Performance optimization
- Additional features building on this work

Current project state:
- [Brief summary of what was just accomplished]
- [Any known gaps or future work identified]

Ready to continue with another orchestration? (Copy the command above and describe your task)
```

**Example:**
```
---

ğŸ’¡ FOLLOW-UP ORCHESTRATION PROMPT:

If there are additional improvements or follow-up tasks to address, you can run:

/cl:orchestrate [describe the follow-up task]

Example follow-up tasks based on what was just completed:
- Add comprehensive test coverage for all new endpoints
- Implement frontend components to consume the new API endpoints
- Add API documentation (OpenAPI/Swagger)
- Set up monitoring and logging for the new features
- Performance testing and optimization

Current project state:
- âœ… Authentication system fully implemented (6 endpoints, JWT rotation)
- âœ… Database migrations configured with Alembic
- âœ… 66 tests created with 84% coverage
- ğŸ“‹ Frontend integration pending
- ğŸ“‹ API documentation pending

Ready to continue with another orchestration? (Copy the command above and describe your task)
```

**Benefits:**
1. **Seamless workflow** - User can immediately continue with next task
2. **Context preservation** - Reminds user of what was just done
3. **Suggests logical next steps** - Helps identify follow-up work
4. **Easy to use** - Just copy and modify the command

---

**CRITICAL:** Steps 1 and 2 MUST be output before any execution. This is non-negotiable.
